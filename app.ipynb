{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!pip install speechbrain\n",
        "!pip install transformers\n",
        "!pip install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bhi_zgTCb3r",
        "outputId": "54483ea0-6d83-4974-ecc2-453161d433b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.0/519.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.10.1)\n",
            "Collecting sentencepiece (from speechbrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.65.0)\n",
            "Collecting huggingface-hub (from speechbrain)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (16.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Collecting ruamel.yaml>=0.17.8 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.17.26-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
            "Installing collected packages: sentencepiece, ruamel.yaml.clib, ruamel.yaml, huggingface-hub, hyperpyyaml, speechbrain\n",
            "Successfully installed huggingface-hub-0.14.1 hyperpyyaml-1.2.0 ruamel.yaml-0.17.26 ruamel.yaml.clib-0.2.7 sentencepiece-0.1.99 speechbrain-0.5.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.29.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=71b4beb7b3dd639eb0dd6b4e2c3e76306ccafda0ae67e43535324fd53ebabfe5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=7bd821aa18d26f2c9ed630ad2ae2aeec911d3f0018d2ac6597a276050528eb5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import torchaudio\n",
        "import streamlit as st\n",
        "from moviepy.editor import VideoFileClip\n",
        "from speechbrain.pretrained import EncoderDecoderASR\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Function to convert video to audio\n",
        "def video2audio(video_path, audio_path):\n",
        "    if not os.path.exists(video_path):\n",
        "        st.error(\"The video file could not be found.\")\n",
        "        return\n",
        "    \n",
        "    # Load the video file\n",
        "    video = VideoFileClip(video_path)\n",
        "\n",
        "    # Extract the audio from the video\n",
        "    audio = video.audio\n",
        "    \n",
        "    # Save the audio file\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "\n",
        "# Function to segment audio into batches\n",
        "def audio2batch(audio_path, batch_dir_path):\n",
        "    # create the output directory if it doesn't already exist\n",
        "    if not os.path.exists(batch_dir_path):\n",
        "        os.makedirs(batch_dir_path)\n",
        "\n",
        "    # set the desired batch size in seconds\n",
        "    batch_size_sec = 5\n",
        "\n",
        "    # load the audio file using torchaudio\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "    # calculate the total duration of the waveform in seconds\n",
        "    duration_sec = waveform.size(1) / sample_rate\n",
        "\n",
        "    # calculate the number of batches needed to cover the entire waveform\n",
        "    num_batches = int(duration_sec / batch_size_sec)\n",
        "\n",
        "    # iterate over the batches\n",
        "    for i in range(num_batches):\n",
        "        # calculate the start and end times of the current batch\n",
        "        start_time_sec = i * batch_size_sec\n",
        "        end_time_sec = (i + 1) * batch_size_sec\n",
        "\n",
        "        # extract the current batch from the waveform\n",
        "        start_sample = int(start_time_sec * sample_rate)\n",
        "        end_sample = int(end_time_sec * sample_rate)\n",
        "        batch_waveform = waveform[:, start_sample:end_sample]\n",
        "\n",
        "        # save the current batch as a new WAV file\n",
        "        output_file_path = os.path.join(batch_dir_path, f\"batch_{i+1}.wav\")\n",
        "        torchaudio.save(output_file_path, batch_waveform, sample_rate)\n",
        "\n",
        "        print(f'audit batch::{output_file_path}')\n",
        "        print(f'batch {i+1} / {num_batches} saved')\n",
        "\n",
        "    # if there is a partial batch at the end, save it as a separate file\n",
        "    if num_batches * batch_size_sec < duration_sec:\n",
        "        # calculate the start and end times of the last batch\n",
        "        start_time_sec = num_batches * batch_size_sec\n",
        "        end_time_sec = duration_sec\n",
        "\n",
        "        # extract the last batch from the waveform\n",
        "        start_sample = int(start_time_sec * sample_rate)\n",
        "        end_sample = int(end_time_sec * sample_rate)\n",
        "        last_batch_waveform = waveform[:, start_sample:end_sample]\n",
        "\n",
        "        # save the last batch as a new WAV file\n",
        "        output_file_path = os.path.join(batch_dir_path, f\"batch_{num_batches+1}.wav\")\n",
        "        torchaudio.save(output_file_path, last_batch_waveform, sample_rate)\n",
        "        print('partial_batch saved.')\n",
        "    return\n",
        "\n",
        "\n",
        "# Function to transcribe audio batches\n",
        "def transcribe(asr_model, batch_dir_path):\n",
        "    # get a list of all the batch files in the directory\n",
        "    batch_files = os.listdir(batch_dir_path)\n",
        "\n",
        "    # sort the batch files based on their numerical order\n",
        "    batch_files.sort(key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
        "\n",
        "    transcriptions = []\n",
        "    for i, batch_file in enumerate(batch_files):\n",
        "        transcription = asr_model.transcribe_file(os.path.join(batch_dir_path, batch_file))\n",
        "        transcriptions.append(transcription)\n",
        "        print(f\"batch {i+1} / {len(batch_files)} transcribed.\")\n",
        "\n",
        "    subtitles = \" \".join(transcriptions)\n",
        "    return subtitles\n",
        "\n",
        "\n",
        "# Set up the Streamlit UI\n",
        "st.title(\"Video Transcription\")\n",
        "\n",
        "\n",
        "# Function to load the ASR models\n",
        "def load_models():\n",
        "    asr_model_1 = EncoderDecoderASR.from_hparams(\n",
        "        source=\"speechbrain/asr-transformer-transformerlm-librispeech\",\n",
        "        savedir=\"pretrained_models/asr-transformer-transformerlm-librispeech\",\n",
        "        run_opts={'device':'cuda'}\n",
        "    )\n",
        "\n",
        "    asr_model_2 = EncoderDecoderASR.from_hparams(\n",
        "        source=\"speechbrain/asr-crdnn-transformerlm-librispeech\",\n",
        "        savedir=\"pretrained_models/asr-crdnn-transformerlm-librispeech\",\n",
        "        run_opts={'device':'cuda'}\n",
        "    )\n",
        "\n",
        "    asr_model_3 = EncoderDecoderASR.from_hparams(\n",
        "        source=\"speechbrain/asr-crdnn-rnnlm-librispeech\",\n",
        "        savedir=\"pretrained_models/asr-crdnn-rnnlm-librispeech\",\n",
        "        run_opts={'device':'cuda'}\n",
        "    )\n",
        "\n",
        "    return asr_model_1, asr_model_2, asr_model_3\n",
        "\n",
        "\n",
        "# Load the ASR models\n",
        "asr_model_1, asr_model_2, asr_model_3 = load_models()\n",
        "\n",
        "# Model selection dropdown\n",
        "model_options = {\n",
        "    \"EncoderDecoderASR (Transformer)\": asr_model_1,\n",
        "    \"EncoderDecoderASR (CRDNN - Transformer)\": asr_model_2,\n",
        "    \"EncoderDecoderASR (CRDNN - RNN)\": asr_model_3,\n",
        "\n",
        "}\n",
        "\n",
        "selected_model = st.selectbox(\"Select the ASR model\", list(model_options.keys()))\n",
        "\n",
        "\n",
        "\n",
        "# File uploader for video selection\n",
        "video_file = st.file_uploader(\"Upload a video file\", type=[\"mp4\"])\n",
        "\n",
        "# Transcription button\n",
        "transcribe_button = st.button(\"Transcribe Video\")\n",
        "\n",
        "# Output area for subtitles\n",
        "subtitles_output = st.empty()\n",
        "\n",
        "# Perform transcription when the button is clicked\n",
        "if transcribe_button and video_file:\n",
        "    # save video file at designated path\n",
        "    video_path = video_file.name\n",
        "    with open(video_path, \"wb\") as f:\n",
        "        f.write(video_file.read())\n",
        "\n",
        "    # Convert video to audio\n",
        "    audio_path = \"audio.wav\"\n",
        "    video2audio(video_path, audio_path)\n",
        "\n",
        "    # Convert audio to batches\n",
        "    batch_dir_path = \"temp_batches/\"\n",
        "    audio2batch(audio_path, batch_dir_path)\n",
        "\n",
        "    # Perform transcription\n",
        "    asr_model = model_options[selected_model]\n",
        "    subtitles = transcribe(asr_model, batch_dir_path)\n",
        "\n",
        "    # Display subtitles\n",
        "    subtitles_output.text(subtitles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlVAomnmAAku",
        "outputId": "3ff33bf7-2281-4936-f2d9-660e9813dbd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HR2_S2B4OH",
        "outputId": "1d3a6a31-1cd8-4a57-eed1-7442bbe5c9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.683s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.121s\n",
            "your url is: https://dry-webs-show.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjinUDexFCYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}